{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bash: \n",
    "\n",
    "pip install spacy\n",
    "\n",
    "python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar el modelo de lenguaje en español\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "\n",
    "#encuentra todos los nombres propios\n",
    "def find_proper_names(text):\n",
    "    doc = nlp(text)\n",
    "    names = [token.text for token in doc if token.pos_ == 'PROPN']\n",
    "    return names #arreglo de nombres propios\n",
    "\n",
    "#encuentra y clasifica los nombres propios\n",
    "def find_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return named_entities\n",
    "\n",
    "\n",
    "\n",
    "#encuentra todas las personas nombradas\n",
    "def encuentra_personas(text):\n",
    "    named_entities = find_named_entities(text)\n",
    "    personas=[]\n",
    "    for entidad in named_entities:\n",
    "        if entidad[1]==\"PER\":\n",
    "            personas.append(entidad[0])\n",
    "\n",
    "    return personas   \n",
    "\n",
    "\n",
    "#encuentra todos los lugares nombradaos\n",
    "def encuentra_lugares(text):\n",
    "    named_entities = find_named_entities(text)\n",
    "    lugares=[]\n",
    "    for entidad in named_entities:\n",
    "        if entidad[1]==\"LOC\":\n",
    "            lugares.append(entidad[0])\n",
    "\n",
    "    return lugares\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(file_path):\n",
    "    try:\n",
    "        # Abrir el archivo en modo lectura\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            # Leer todo el contenido del archivo\n",
    "            file_content = file.read()\n",
    "        # Devolver el contenido como un string \n",
    "        return file_content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo {file_path} no fue encontrado.\")\n",
    "        return \"\"\n",
    "    except IOError:\n",
    "        print(f\"Error: No se pudo leer el archivo {file_path}.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades nombradas: [('FUGA', 'ORG'), ('DESPERDICIO DE AGUA', 'ORG'), ('AFECTACIONES', 'ORG'), ('Comisión de Agua', 'ORG'), ('Estado de México', 'LOC'), ('CAEM', 'LOC'), ('Tejupilco', 'LOC'), ('Temascaltepec', 'LOC'), ('Agencia Quadratín', 'ORG'), ('Real de Arriba', 'LOC'), ('Temascaltepec', 'LOC'), ('Instituto Temascaltepec', 'LOC'), ('Real de Arriba', 'ORG'), ('Tejupilco', 'ORG'), ('El Sr Raúl Domínguez de Real de Arriba', 'MISC'), ('“', 'LOC'), ('Tejupilco', 'LOC'), ('Tejupilco', 'LOC'), ('Temascaltepec', 'LOC'), ('Tejupilco', 'ORG')]\n",
      "Nombres propios: ['FUGA', 'DESPERDICIO', 'AGUA', 'Cabe', 'Comisión', 'Agua', 'Estado', 'México', 'CAEM', 'Tejupilco', 'Temascaltepec', 'Agencia', 'Quadratín', 'https://edomex.quadratin.com.mx/Rehabilitaran-sistema-de-agua-potable-en-Tejupilco/', 'Real', 'Arriba', 'Temascaltepec', 'Instituto', 'Temascaltepec', 'Real', 'Arriba', 'Tejupilco', 'Sr', 'Raúl', 'Domínguez', 'Real', 'Arriba', '“', 'Tejupilco', 'piedras', 'Tejupilco', 'Temascaltepec', 'Tejupilco']\n",
      "Personas: []\n",
      "Lugares: ['Estado de México', 'CAEM', 'Tejupilco', 'Temascaltepec', 'Real de Arriba', 'Temascaltepec', 'Instituto Temascaltepec', '“', 'Tejupilco', 'Tejupilco', 'Temascaltepec']\n"
     ]
    }
   ],
   "source": [
    "#prueba texto 1\n",
    "file_path = 'posts/prueba1.txt'\n",
    "file_string = read_file_to_string(file_path)\n",
    "\n",
    "sample_post = file_string\n",
    "named_entities = find_named_entities(sample_post)\n",
    "print(\"Entidades nombradas:\", named_entities)\n",
    "\n",
    "proper_names = find_proper_names(sample_post)\n",
    "print(\"Nombres propios:\", proper_names)\n",
    "\n",
    "personas = encuentra_personas(sample_post)\n",
    "print(\"Personas:\", personas)\n",
    "\n",
    "lugares = encuentra_lugares(sample_post)\n",
    "print(\"Lugares:\", lugares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades nombradas: [('CEDH', 'MISC'), ('Armando Linares López', 'MISC'), ('Zitácuaro', 'MISC'), ('Policía Michoacán', 'MISC'), ('Esta semana un joven presentó una queja', 'MISC'), ('Comisión Estatal de Derechos Humanos', 'ORG'), ('CEDH', 'MISC'), ('Policía Michoacán', 'MISC'), ('Policía Michoacán', 'MISC'), ('Carpinteros', 'LOC'), ('No.', 'MISC'), ('Al ser detenido para revisarlo', 'MISC'), ('Rincón de Curungueo', 'LOC'), ('Amenazándolo', 'PER'), ('Fiscalía', 'MISC'), ('“De todas formas tenemos', 'MISC'), ('Fiscalía', 'MISC'), ('Así', 'PER'), ('“', 'LOC'), ('Ministerio Público', 'LOC'), ('Una vez que lo dejaron en libertad', 'MISC'), ('policías', 'PER'), ('habían', 'PER'), ('Cabe hacer mención', 'MISC'), ('Ahora', 'MISC')]\n",
      "Nombres propios: ['CEDH', 'Armando', 'Linares', 'López', 'Zitácuaro', 'Policía', 'Michoacán', 'Comisión', 'Estatal', 'Derechos', 'Humanos', 'CEDH', 'Policía', 'Michoacán', 'Policía', 'Michoacán', 'Carpinteros', 'Rincón', 'Curungueo', 'Amenazándolo', 'Fiscalía', '“', 'Fiscalía', '“', 'Ministerio', 'Público']\n",
      "Personas: ['Amenazándolo', 'Así', 'policías', 'habían']\n",
      "Lugares: ['Carpinteros', 'Rincón de Curungueo', '“', 'Ministerio Público']\n"
     ]
    }
   ],
   "source": [
    "#prueba texto 2\n",
    "file_path = 'posts/prueba2.txt'\n",
    "file_string = read_file_to_string(file_path)\n",
    "\n",
    "sample_post = file_string\n",
    "named_entities = find_named_entities(sample_post)\n",
    "print(\"Entidades nombradas:\", named_entities)\n",
    "\n",
    "proper_names = find_proper_names(sample_post)\n",
    "print(\"Nombres propios:\", proper_names)\n",
    "\n",
    "personas = encuentra_personas(sample_post)\n",
    "print(\"Personas:\", personas)\n",
    "\n",
    "lugares = encuentra_lugares(sample_post)\n",
    "print(\"Lugares:\", lugares)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 115MB/s]                     \n",
      "2024-08-22 16:18:14 INFO: Downloaded file to /Users/mariajosevelazquez/stanza_resources/resources.json\n",
      "2024-08-22 16:18:14 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.8.0/models/default.zip: 100%|██████████| 642M/642M [02:35<00:00, 4.12MB/s] \n",
      "2024-08-22 16:20:52 INFO: Downloaded file to /Users/mariajosevelazquez/stanza_resources/es/default.zip\n",
      "2024-08-22 16:20:54 INFO: Finished downloading models and saved to /Users/mariajosevelazquez/stanza_resources\n",
      "2024-08-22 16:20:54 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 8.00MB/s]                    \n",
      "2024-08-22 16:20:54 INFO: Downloaded file to /Users/mariajosevelazquez/stanza_resources/resources.json\n",
      "2024-08-22 16:20:55 INFO: Loading these models for language: es (Spanish):\n",
      "====================================\n",
      "| Processor    | Package           |\n",
      "------------------------------------\n",
      "| tokenize     | combined          |\n",
      "| mwt          | combined          |\n",
      "| pos          | combined_charlm   |\n",
      "| lemma        | combined_nocharlm |\n",
      "| constituency | combined_charlm   |\n",
      "| depparse     | combined_charlm   |\n",
      "| sentiment    | tass2020_charlm   |\n",
      "| ner          | conll02           |\n",
      "====================================\n",
      "\n",
      "2024-08-22 16:20:55 INFO: Using device: cpu\n",
      "2024-08-22 16:20:55 INFO: Loading: tokenize\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:56 INFO: Loading: mwt\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/mwt/trainer.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:56 INFO: Loading: pos\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:56 INFO: Loading: lemma\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/lemma/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:56 INFO: Loading: constituency\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/constituency/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:56 INFO: Loading: depparse\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/depparse/trainer.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:56 INFO: Loading: sentiment\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/classifiers/trainer.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:56 INFO: Loading: ner\n",
      "/Users/mariajosevelazquez/Desktop/AnalisisPostsPeriodistas/myenv/lib/python3.11/site-packages/stanza/models/ner/trainer.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-22 16:20:57 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('es')\n",
    "nlp = stanza.Pipeline('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función que extrae los nombres de las personas en un texto\n",
    "def extrae_nombres_personas(text):\n",
    "    doc = nlp(text)\n",
    "    personas = []\n",
    "    for sentence in doc.sentences:\n",
    "        for ent in sentence.ents:\n",
    "            if ent.type == 'PER' and ent.text not in personas:\n",
    "                personas.append(ent.text)\n",
    "    return personas\n",
    "\n",
    "# función que extrae los nombres de los lugares en un texto\n",
    "def extrae_lugares(text):\n",
    "    doc = nlp(text)\n",
    "    lugares = []\n",
    "    for sentence in doc.sentences:\n",
    "        for ent in sentence.ents:\n",
    "            if ent.type == 'LOC' and ent.text not in lugares:\n",
    "                lugares.append(ent.text)\n",
    "    return lugares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averiguar_personas(text):\n",
    "    nombres_personas = extrae_nombres_personas(text)\n",
    "    personas = {}\n",
    "    for nombre in nombres_personas:\n",
    "        #Funcionamiento de la función\n",
    "        personas.append(nombre)\n",
    "    return personas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sr Raúl Domínguez de Real de Arriba', 'Tejupilco']\n",
      "['Temascaltepec', 'Real de Arriba', 'Instituto Temascaltepec', 'Tejupilco']\n"
     ]
    }
   ],
   "source": [
    "#prueba texto 1\n",
    "\n",
    "file_path = 'posts/prueba1.txt'\n",
    "file_string = read_file_to_string(file_path)\n",
    "\n",
    "print(extrae_nombres_personas(file_string))\n",
    "print(extrae_lugares(file_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Armando Linares López', 'No.']\n",
      "['Carpinteros', 'Rincón de Curungueo']\n"
     ]
    }
   ],
   "source": [
    "#prueba texto 2\n",
    "\n",
    "file_path = 'posts/prueba2.txt'\n",
    "file_string = read_file_to_string(file_path)\n",
    "\n",
    "print(extrae_nombres_personas(file_string))\n",
    "print(extrae_lugares(file_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rivera Soto']\n",
      "['Israel C. Téllez”', 'Veracruz']\n"
     ]
    }
   ],
   "source": [
    "#prueba texto 3\n",
    "\n",
    "file_path = 'posts/prueba3.txt'\n",
    "file_string = read_file_to_string(file_path)\n",
    "\n",
    "print(extrae_nombres_personas(file_string))\n",
    "print(extrae_lugares(file_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
